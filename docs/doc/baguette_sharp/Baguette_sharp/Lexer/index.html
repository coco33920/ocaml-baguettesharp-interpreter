<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Lexer (baguette_sharp.Baguette_sharp.Lexer)</title><link rel="stylesheet" href="../../../odoc.css"/><meta charset="utf-8"/><meta name="generator" content="odoc 2.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../../index.html">baguette_sharp</a> &#x00BB; <a href="../index.html">Baguette_sharp</a> &#x00BB; Lexer</nav><header class="odoc-preamble"><h1>Module <code><span>Baguette_sharp.Lexer</span></code></h1><p>General lexer module : generate lexers char by char or word by word (default)</p></header><div class="odoc-content"><div class="odoc-spec"><div class="spec value" id="val-read_token" class="anchored"><a href="#val-read_token" class="anchor"></a><code><span><span class="keyword">val</span> read_token : <span>string <span class="arrow">&#45;&gt;</span></span> <span>bool <span class="arrow">&#45;&gt;</span></span> <a href="../Token/index.html#type-token_type">Token.token_type</a> * int</span></code></div><div class="spec-doc"><p>Take a word and if the lexer is between quotes and returns the corresponding token with Token#string_to_token</p></div></div><div class="odoc-spec"><div class="spec value" id="val-recognized_token" class="anchored"><a href="#val-recognized_token" class="anchor"></a><code><span><span class="keyword">val</span> recognized_token : <span>string list</span></span></code></div></div><div class="odoc-spec"><div class="spec value" id="val-max_lst" class="anchored"><a href="#val-max_lst" class="anchor"></a><code><span><span class="keyword">val</span> max_lst : <span><span class="type-var">'a</span> <span class="arrow">&#45;&gt;</span></span> <span><span><span class="type-var">'a</span> list</span> <span class="arrow">&#45;&gt;</span></span> <span class="type-var">'a</span></span></code></div><div class="spec-doc"><p>Returns the maximum of a list</p></div></div><div class="odoc-spec"><div class="spec value" id="val-is_a_token_a_keyword" class="anchored"><a href="#val-is_a_token_a_keyword" class="anchor"></a><code><span><span class="keyword">val</span> is_a_token_a_keyword : <span>string <span class="arrow">&#45;&gt;</span></span> int</span></code></div><div class="spec-doc"><p>Take a string and returns the biggest token matching the keyword</p></div></div><div class="odoc-spec"><div class="spec value" id="val-type_inference_algorithm" class="anchored"><a href="#val-type_inference_algorithm" class="anchor"></a><code><span><span class="keyword">val</span> type_inference_algorithm : <span>string <span class="arrow">&#45;&gt;</span></span> <a href="../Token/index.html#type-token_type">Token.token_type</a></span></code></div><div class="spec-doc"><p>Runs the type inference algorithm</p></div></div><div class="odoc-spec"><div class="spec value" id="val-extract_token" class="anchored"><a href="#val-extract_token" class="anchor"></a><code><span><span class="keyword">val</span> extract_token : <span>string <span class="arrow">&#45;&gt;</span></span> <span>int <span class="arrow">&#45;&gt;</span></span> <a href="../Token/index.html#type-token_type">Token.token_type</a> * <a href="../Token/index.html#type-token_type">Token.token_type</a></span></code></div><div class="spec-doc"><p>Take a string with a token in it and returns a couple of Tokens</p></div></div><div class="odoc-spec"><div class="spec value" id="val-generate_token_with_chars" class="anchored"><a href="#val-generate_token_with_chars" class="anchor"></a><code><span><span class="keyword">val</span> generate_token_with_chars : <span><span class="xref-unresolved">Stdlib</span>.String.t <span class="arrow">&#45;&gt;</span></span> <span><a href="../Token/index.html#type-token_type">Token.token_type</a> list</span></span></code></div><div class="spec-doc"><p>The char by char lexer</p></div></div><div class="odoc-spec"><div class="spec value" id="val-generate_token" class="anchored"><a href="#val-generate_token" class="anchor"></a><code><span><span class="keyword">val</span> generate_token : <span>string <span class="arrow">&#45;&gt;</span></span> <span><a href="../Token/index.html#type-token_type">Token.token_type</a> list</span></span></code></div><div class="spec-doc"><p>The word by word lexers</p></div></div><div class="odoc-spec"><div class="spec value" id="val-validate_parenthesis_and_quote" class="anchored"><a href="#val-validate_parenthesis_and_quote" class="anchor"></a><code><span><span class="keyword">val</span> validate_parenthesis_and_quote : <span><span><a href="../Token/index.html#type-token_type">Token.token_type</a> list</span> <span class="arrow">&#45;&gt;</span></span> <a href="../Parser/index.html#type-parameters">Parser.parameters</a></span></code></div><div class="spec-doc"><p>A function to count the parenthesis and validate if every parenthesis are closed and every quotes are doubled</p></div></div></div></body></html>